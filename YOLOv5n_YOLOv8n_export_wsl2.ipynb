{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.99 ðŸš€ Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Setup complete âœ… (12 CPUs, 15.6 GB RAM, 149.0/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "display.clear_output()\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = f'\"/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/dataset/COCO2020_15.yolov8\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.99 ðŸš€ Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 168 layers, 3008573 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/detect/train/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 19, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.28...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as runs/detect/train/weights/best.onnx (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n",
      "[05/14/2023-12:41:57] [TRT] [I] [MemUsageChange] Init CUDA: CPU +564, GPU +0, now: CPU 3424, GPU 2313 (MiB)\n",
      "[05/14/2023-12:42:01] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +79, GPU -47, now: CPU 3522, GPU 2248 (MiB)\n",
      "[05/14/2023-12:42:01] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/14/2023-12:42:01] [TRT] [I] Input filename:   runs/detect/train/weights/best.onnx\n",
      "[05/14/2023-12:42:01] [TRT] [I] ONNX IR version:  0.0.8\n",
      "[05/14/2023-12:42:01] [TRT] [I] Opset version:    17\n",
      "[05/14/2023-12:42:01] [TRT] [I] Producer name:    pytorch\n",
      "[05/14/2023-12:42:01] [TRT] [I] Producer version: 2.0.1\n",
      "[05/14/2023-12:42:01] [TRT] [I] Domain:           \n",
      "[05/14/2023-12:42:01] [TRT] [I] Model version:    0\n",
      "[05/14/2023-12:42:01] [TRT] [I] Doc string:       \n",
      "[05/14/2023-12:42:01] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/14/2023-12:42:02] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 19, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as runs/detect/train/weights/best.engine\n",
      "[05/14/2023-12:42:02] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +32, now: CPU 3537, GPU 2329 (MiB)\n",
      "[05/14/2023-12:42:02] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 3537, GPU 2363 (MiB)\n",
      "[05/14/2023-12:42:02] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/14/2023-12:43:28] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[05/14/2023-12:43:28] [TRT] [I] Total Host Persistent Memory: 179488\n",
      "[05/14/2023-12:43:28] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[05/14/2023-12:43:28] [TRT] [I] Total Scratch Memory: 0\n",
      "[05/14/2023-12:43:28] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n",
      "[05/14/2023-12:43:28] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 11.1375ms to assign 6 blocks to 130 nodes requiring 18124800 bytes.\n",
      "[05/14/2023-12:43:28] [TRT] [I] Total Activation Memory: 18124800\n",
      "[05/14/2023-12:43:29] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[05/14/2023-12:43:29] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[05/14/2023-12:43:29] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 93.6s, saved as runs/detect/train/weights/best.engine (14.8 MB)\n",
      "\n",
      "Export complete (97.3s)\n",
      "Results saved to \u001b[1m/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/runs/detect/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/detect/train/weights/best.engine imgsz=640 \n",
      "Validate:        yolo val task=detect model=runs/detect/train/weights/best.engine imgsz=640 data=/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/dataset/COCO2020_15.yolov8/data.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!yolo export model=runs/detect/train/weights/best.pt data={dataset_location}/data.yaml format=engine device=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/dataset/COCO2020_15.yolov8/datav5.yaml, weights=['runs/train/exp/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=0, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['engine']\n",
      "fatal: cannot change to '/mnt/c/Users/Fomichev': Not a directory\n",
      "YOLOv5 ðŸš€ 2023-5-10 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1779460 parameters, 0 gradients, 4.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/train/exp/weights/best.pt with output shape (1, 25200, 20) (3.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0...\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.4s, saved as runs/train/exp/weights/best.onnx (7.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n",
      "[05/14/2023-12:44:54] [TRT] [I] [MemUsageChange] Init CUDA: CPU +563, GPU +0, now: CPU 3404, GPU 1568 (MiB)\n",
      "[05/14/2023-12:44:58] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +79, GPU +0, now: CPU 3502, GPU 1568 (MiB)\n",
      "/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/yolov5/export.py:299: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = workspace * 1 << 30\n",
      "[05/14/2023-12:44:58] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/14/2023-12:44:58] [TRT] [I] Input filename:   runs/train/exp/weights/best.onnx\n",
      "[05/14/2023-12:44:58] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[05/14/2023-12:44:58] [TRT] [I] Opset version:    12\n",
      "[05/14/2023-12:44:58] [TRT] [I] Producer name:    pytorch\n",
      "[05/14/2023-12:44:58] [TRT] [I] Producer version: 2.0.1\n",
      "[05/14/2023-12:44:58] [TRT] [I] Domain:           \n",
      "[05/14/2023-12:44:58] [TRT] [I] Model version:    0\n",
      "[05/14/2023-12:44:58] [TRT] [I] Doc string:       \n",
      "[05/14/2023-12:44:58] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/14/2023-12:44:58] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 25200, 20) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as runs/train/exp/weights/best.engine\n",
      "/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/yolov5/export.py:326: DeprecationWarning: Use build_serialized_network instead.\n",
      "  with builder.build_engine(network, config) as engine, open(f, 'wb') as t:\n",
      "[05/14/2023-12:44:58] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +32, now: CPU 3512, GPU 1600 (MiB)\n",
      "[05/14/2023-12:44:58] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 3512, GPU 1634 (MiB)\n",
      "[05/14/2023-12:44:58] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[05/14/2023-12:47:01] [TRT] [I] Detected 1 inputs and 4 output network tensors.\n",
      "[05/14/2023-12:47:01] [TRT] [I] Total Host Persistent Memory: 159328\n",
      "[05/14/2023-12:47:01] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[05/14/2023-12:47:01] [TRT] [I] Total Scratch Memory: 0\n",
      "[05/14/2023-12:47:01] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n",
      "[05/14/2023-12:47:01] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 14.0614ms to assign 8 blocks to 139 nodes requiring 17817604 bytes.\n",
      "[05/14/2023-12:47:01] [TRT] [I] Total Activation Memory: 17817604\n",
      "[05/14/2023-12:47:02] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[05/14/2023-12:47:02] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[05/14/2023-12:47:02] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 128.6s, saved as runs/train/exp/weights/best.engine (10.8 MB)\n",
      "\n",
      "Export complete (130.7s)\n",
      "Results saved to \u001b[1m/mnt/c/Users/Fomichev Nikita/Desktop/Study/tadimo/coursework/yolov5/runs/train/exp/weights\u001b[0m\n",
      "Detect:          python detect.py --weights runs/train/exp/weights/best.engine \n",
      "Validate:        python val.py --weights runs/train/exp/weights/best.engine \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/exp/weights/best.engine')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights runs/train/exp/weights/best.pt --data {dataset_location}/datav5.yaml --include engine --device 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
